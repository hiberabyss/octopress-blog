<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: FileSystem | 蛰渊-成长的轨迹]]></title>
  <link href="http://hiberabyss.github.io/blog/categories/FileSystem/atom.xml" rel="self"/>
  <link href="http://hiberabyss.github.io/"/>
  <updated>2013-07-17T19:46:34+08:00</updated>
  <id>http://hiberabyss.github.io/</id>
  <author>
    <name><![CDATA[hiberabyss]]></name>
    <email><![CDATA[liuhb90@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Lustre原理及优化]]></title>
    <link href="http://hiberabyss.github.io/blog/20130716/lustre-internal/"/>
    <updated>2013-07-16T16:30:00+08:00</updated>
    <id>http://hiberabyss.github.io/blog/20130716/lustre-internal</id>
    <content type="html"><![CDATA[<p>介绍Lustre的内部细节及一些优化措施。</p>

<!--more-->

<h2 id="lustre-stripe">Lustre Stripe</h2>
<p>Lustre采用对象存储技术，将大文件分片存储在多个OST上。分片的参数包括<code>stripe_count</code>和<code>stripe_size</code>，即所要使用的OST的数量以及分片的大小，默认分别为<code>1</code>和<code>1MB</code>。可以通过<code>lfs setstripe</code>命令进行设定，子目录继承父目录的分片模式。Lustre在创建文件时就按照分片模式和OST选择算法，预先创建好文件所需的OST对象。数据写入后，文件的分片不能修改，现在还未实现OST存储空间的自动均衡。</p>

<p>OST选择算法：
1. Round-Robin：任意两个OST剩余存储容量之差小于<code>20%</code>时采用该算法；以顺序轮转方式选择OST，算法非常高效。
2. 随机加权算法：存在两个OST剩余空间之差大于<code>20%</code>时采用该算法；Lustre维护着一张剩余空间的优先列表，采用随机算法在此列表中选择OST，会产生开销并影响性能；当任意两个OST剩余容量之差小于<code>20%</code>时，继续选用<code>Round-Robin</code>算法。</p>

<h2 id="lustre">Lustre性能优化</h2>

<ol>
  <li>禁用所有客户端的<code>LNET debug</code>功能：<code>sysctl -w lnet.debug=0</code>。</li>
  <li>增加客户端Dirty Cache大小：<code>lctl set_param osc./*.max_dirty_mb=256</code>，缺省为32MB，增大缓存将提升I/O性能，但数据丢失的风险也随之增大。</li>
  <li>增加RPC并行数量：echo 32 &gt; /proc/fs/lustre/osc/<em>-OST000</em>/max_rpcs_in_flight，缺省为8，提升至32将提高数据和元数据性能。不利之处是如果服务器压力很大，可能反而会影响性能。</li>
</ol>

<h2 id="section">参考资料</h2>
<p><a href="http://blog.csdn.net/liuben/article/details/6455736">Lustre I/O性能特点与最佳实践</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Lustre的安装与配置]]></title>
    <link href="http://hiberabyss.github.io/blog/20130624/lustre-configture/"/>
    <updated>2013-06-24T12:37:00+08:00</updated>
    <id>http://hiberabyss.github.io/blog/20130624/lustre-configture</id>
    <content type="html"><![CDATA[<p>Lustre是一个分布式文件系统，由MDS（元数据服务器）、OSS（对象存储服务器）和Client（客户端）三部分组成。其中MDS和OSS都可以有多个节点，通过MGS进行管理，MGS只能有一个。</p>

<h2 id="section">主要内容</h2>
<ul>
  <li>安装环境  </li>
  <li>Lustre的安装</li>
  <li>Lustre的配置</li>
  <li>用于Lustre管理的实用工具</li>
  <li>遇到的问题与解决方案</li>
  <li>有创意的Idea</li>
</ul>

<!--more-->

<h2 id="section-1">安装环境</h2>
<ul>
  <li>操作系统：CentOS 6.3 (x86_64)</li>
  <li>内核版本：2.6.32-279</li>
  <li>Lustre版本：2.3</li>
  <li>Lustre节点：一个MGS和MDT，使用同一个服务器；多个OSS。</li>
</ul>

<h2 id="lustre">Lustre的安装</h2>
<p>安装之前，对系统环境有如下要求：   </p>

<ol>
  <li>必须已安装<em>net-snmp</em>，否则在安装<em>lustre-version.rpm</em>时会报错；</li>
  <li>selinux必须被设置为disabled，如果未关闭则在<em>mkfs.lustre</em>操作时会报错；可通过sestatus查看selinux当前状态，如果为enforcing则表示未关闭；可通过命令<code>setenforce [permissive|0]</code>临时性关闭;永久关闭则需要修改配置文件<em>/etc/selinux/config</em>，做如下修改重启后生效：</li>
</ol>

<p><code>bash
SELINUX=disabled
</code></p>

<p>下载<a href="http://downloads.whamcloud.com/public/e2fsprogs/latest/el6/RPMS/x86_64/">e2fsprogs</a>并安装：</p>

<p><code>bash
rpm -Uvh --nodeps \
e2fsprogs-devel-1.42.7.wc1-7.el6.x86_64.rpm \
e2fsprogs-libs-1.42.7.wc1-7.el6.x86_64.rpm \
e2fsprogs-1.42.7.wc1-7.el6.x86_64.rpm \
libcom_err-devel-1.42.7.wc1-7.el6.x86_64.rpm \
libcom_err-1.42.7.wc1-7.el6.x86_64.rpm \
libss-devel-1.42.7.wc1-7.el6.x86_64.rpm \
libss-1.42.7.wc1-7.el6.x86_64.rpm
</code></p>

<p>下载<a href="http://downloads.whamcloud.com/public/lustre/lustre-2.3.0/el6/server/RPMS/x86_64/">kernel</a>包并安装（如果要使用InfiniBind连接方式，则必须安装kernel-ib-version包，且需要卸载系统中已经安装的以mlnx开头的kenel包）：</p>

<p><code>bash
rpm -ivh \
kernel-firmware-2.6.32-279.5.1.el6_lustre.gb16fe80.x86_64.rpm \
kernel-devel-2.6.32-279.5.1.el6_lustre.gb16fe80.x86_64.rpm \
kernel-2.6.32-279.5.1.el6_lustre.gb16fe80.x86_64.rpm \
kernel-ib-version
</code></p>

<p>下载并安装<a href="http://downloads.whamcloud.com/public/lustre/lustre-2.3.0/el6/server/RPMS/x86_64/">Lustre</a>：</p>

<p><code>bash
rpm -ivh \
lustre-ldiskfs-3.3.0-2.6.32_279.5.1.el6_lustre.gb16fe80.x86_64.x86_64.rpm \
lustre-modules-2.3.0-2.6.32_279.5.1.el6_lustre.gb16fe80.x86_64.x86_64.rpm \
lustre-2.3.0-2.6.32_279.5.1.el6_lustre.gb16fe80.x86_64.x86_64.rpm
</code></p>

<h2 id="lustre-1">Lustre的配置</h2>

<p>配置Lustre所使用的接口名称以及相对应的别名；</p>

<ul>
  <li>Lustre默认使用的是第一个网络接口，默认的名称为<code>tcp0</code>；</li>
  <li>如果需要使用光纤接口，则创建<em>/etc/modprobe.d/lnet.conf</em>文件，写入以下内容：</li>
</ul>

<p><code>bash
options lnet networks="o2ib0(ib0)"
</code></p>

<p>使用光纤接口前需要先确定光纤接口是否配置正常：使用<code>ifconfig</code>和<code>ibv_devinfo</code>查看相关端口是否启动，ip地址是否配置正确，接口状态等。查看通过光纤接口是否可以和其它节点联通。</p>

<p>如果使用的是<code>mlnx</code>驱动，则在加载<code>lustre</code>模块时会报错，需要先卸载如下的几个包</p>

<p><code>bash
rpm -qa | grep 'kernel' | grep 'mlnx'
</code></p>

<p>如果光纤接口出现故障，则首先通过<code>lspci</code>确定相关硬件是否存在；接着确定<code>openibd</code>服务是否开启，如果未开启则利用以下命令启动并设置开机启动</p>

<p><code>bash
service openibd start
chkconfig openibd on
#查看开机启动是否设置成功
chkconfig --list openibd
</code></p>

<p>载入相关模块：</p>

<p><code>bash
modprobe lustre
modprobe ldiskfs
modprobe lnet
</code></p>

<p>这时可以查看<em>/sys/modules/lnet/prarameters/networks</em>内容，以确定<em>lnet.conf</em>中的配置信息是否已经加载至内核。</p>

<p>在MDS上的创建Lustre文件系统，并挂载：</p>

<p><code>bash
mkfs.lustre --fsname=mylustre --mdt --mgs --index=0 --reformat /dev/sdb1
mount.lustre /dev/sdb1 /mnt/mdt
</code></p>

<p>其中<em>fsname</em>为安装的lustre文件系统的标志，在MGS、MDS和OSS中都必须保持一致，在客户端挂在Lustre文件系统时也会使用到这个名字，长度不能超过8个字符；本例中MGS和MDS使用同一个服务器；<em>reformat</em>会对磁盘进行重新格式化处理。</p>

<p>在OSS上创建Lustre文件系统，并挂载：</p>

<p><code>
mkfs.lustre --fsname=mylustre --ost --reformat --index=num --mgsnode=host_mds@o2ib0 /dev/sdb2
mount.lustre /dev/sdb2 /mnt/ost
</code></p>

<p>必须要在MDT的文件系统挂在之后才能挂载OST的文件系统；<em>host_mds</em>为mds的ip地址或者已经写入<em>hosts</em>文件的主机名，<em>o2ib0</em>和<em>lnet.conf</em>中写入的内容保持一致。
如果出现无法连接的情况，则可能是防火墙的原因，可以关闭<em>iptables</em>服务：<code>service iptables stop</code></p>

<p>客户端的挂载：</p>

<p><code>
mount.lustre host_mds@o2ib0:/mylustre /mnt/lustre
</code></p>

<h2 id="section-2">实用工具</h2>
<p>lctl：可以直接在终端运行进入交互的命令方式或者直接输入命令。</p>

<p><code>
lctl network up
lctl list_nids	#可以查看当前实际的ip地址，以确定是否使用了正确的接口
lctl ping nids	#用来检查OSS和MGS连接是否正常
lctl dl		#查看当前的设备
</code></p>

<p>可以通过<em>lfs</em>命令获取已挂载的<em>lustre</em>文件系统信息：</p>

<p><code>
lfs df -h
</code></p>

<p>或者对文件系统的文件写入方式等进行配置：</p>

<p><code>
lfs setstripe -c -1 -S 128M /mnt/lustre/
</code></p>

<p>其中<code>-c -1</code>表示写入到所有的OSS中，<code>-S 128M</code>表示文件分块的大小为128M；上面是对整个文件系统进行设置，也可以单独地对某个文件或者文件夹进行设置；设置完后可以通过如下命令查看配置信息是否正确：</p>

<p><code>
lfs getstripe /mnt/lustre
</code></p>

<p>利用<code>tunefs.lustre</code>可以查看已建立的lustre文件系统的信息，并对部分信息进行调整。</p>

<h2 id="iozone">利用iozone进行测试</h2>
<p>iozone是对文件系统的读写性能进行测试的工具</p>

<p><code>bash
#单个测试文件大小
FILE_SIZE="16g"
#进行读写的进程的数量
THREAD_NUM="16"
#总的读写数据量
TOTAL_FILESIZE=$((FILE_SIZE*THREAD_NUM))
#-i 0: 代表write/rewrite
#-i 1: 代表read/reread
#-i 2: 表示random-write/random-read
#-o: 表示在写后要立即进行同步，去除该参数后可有效提高写速度
#-+n: 不进行重复测试，即不会进行rewrite和reread
/path/to/iozone -e -c -s $TOTAL_FILESIZE -r $RECSIZE -+m $NODELIST -+k -i 0 -i 1 -t  $THREAD_NUM -o -w -+n&gt;&gt; $OUTPUTFILE
</code></p>

<p>其中<code>$NODELIST</code>是下面一种格式的节点配置文件，每一行代表一个客户端，用空格区分为不同的列，每一列的含义如下：</p>

<ol>
  <li>客户端名称</li>
  <li>要测试的文件系统的一个目录</li>
  <li>iozone的可执行文件路径</li>
  <li>文件名，相同的主机名但不同的文件名也表示一个单独的读写测试进程</li>
</ol>

<p><code>
snode17 /mnt/lustre /path/to/iozone file170
snode18 /mnt/lustre /path/to/iozone file180
snode17 /mnt/lustre /path/to/iozone file171
snode18 /mnt/lustre /path/to/iozone file181
</code></p>

<h2 id="p-problemc-causer-resolve">遇到的问题及解决方法（P-Problem，C-Cause，R-Resolve）</h2>
<p>P：安装完重启之后，系统无法启动。<br />
C：因为启动分区太小，只有100M大小，而<em>Lustre</em>生成的<em>initramfs</em>太大，大概有65M，最后导致生成的文件不完整，所以无法启动；在<em>lustre-module-version</em>的安装过程中产生，会报文件写入错误。<br />
R：调整分区大小比较困难，也不方便进行批量处理；就不是用单独的启动分区，把<em>grub</em>重新安装到<em>/dev/sda</em>上，卸载启动分区，把内核等文件复制到根文件系统的<em>/boot</em>目录下，修改<em>grub.conf</em>文件，直接通过根文件系统下的<em>/boot</em>目录中的内核进行启动。  </p>

<p>P：安装完Lustre并成功启动后，在执行<em>mount.lustre</em>操作之后，就会断开了ssh连接。<br />
C：主机上提示<em>out of memory</em>提示，并killing一大堆进程，至今没搞明白为什么会出现内存不足的问题，当时机器的配置是2G内存，我在虚拟机中实验时，设置1G的内存，也没有出现这个错误。<br />
R：去除内核参数<em>mem=2048M</em>之后，内存变为了32G，一切就恢复正常了。  </p>

<h2 id="idea">比较有创意的Idea</h2>
<p>需要对<em>/dev/sdb</em>进行分区，就在一台机器上利用<code>fdisk</code>按要求分区后，拷贝出该硬盘前512字节启动分区内容：</p>

<p><code>bash
dd if=/dev/sdb of=boot512.img bs=512 count=1
</code></p>

<p>之后把这个文件写入其他机器的<em>/dev/sdb</em>硬盘，便可完成分区，这样便方便进行批量处理了：</p>

<p><code>
dd if=boot512.img of=/dev/sdb bs=512 count=1
</code></p>

<p>在用<code>fdisk</code>分完区后，在<em>/dev/sdb#</em>中并没有及时地反映出分区后的结果，此时运行<code>partprobe /dev/sdb</code>命令即可。</p>

<h2 id="section-3">参考文献：</h2>
<p><a href="http://xiaolangit.blog.51cto.com/3343422/1195060">51CTO：Lustre-2.3的安装</a></p>
]]></content>
  </entry>
  
</feed>
